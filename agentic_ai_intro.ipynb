{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 20px; text-align: center; color: white;\">\n",
    "    <div>\n",
    "        <h1 style=\"margin: 10px 0;\"><strong>Introduction to Agentic AI with LangGraph</strong></h1>\n",
    "        <h2>Matthew Sayer, AI Engineer</h2>\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color: #ffffff;\"><strong>Part 1:</strong></span> What is Agentic AI and LangGraph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Agentic AI**: An introduction\n",
    "\n",
    "<strong>Agentic AI refers to AI systems designed to function as autonomous \"agents\" that can:</strong>\n",
    "\n",
    "1. Plan and execute complex tasks by breaking them into logical steps\n",
    "2. Make decisions independently based on goals, context, and available information provided by the system and user prompts\n",
    "3. Adapt dynamically to changing conditions and unexpected outcomes, through the use of LLM-driven routing\n",
    "4. Self-improve through feedback loops and iterative approaches\n",
    "5. Utilise various tools and capabilities as needed to accomplish objectives\n",
    "6. Unlike traditional conversational AI flows that simply respond to user prompts with static outputs, agentic AI systems actively manage their own workflows, determine what information they need, decide which actions to take, and persist until objectives are achieved.\n",
    "\n",
    "### Key Components of Agentic Systems\n",
    "1. Memory mechanisms that maintain context across multiple steps, stored in a State\n",
    "2. Reasoning capabilities to evaluate options and make decisions, powered by LLMs\n",
    "3. Planning functions to break complex tasks into achievable steps, through structured Nodes\n",
    "4. Tool integration to expand capabilities far beyond language processing\n",
    "\n",
    "#### Traditional LLM applications follow a simple pattern:\n",
    "\n",
    "User provides prompt → LLM generates response → Interaction ends\n",
    "\n",
    "#### Agentic systems transform this into a continuous process:\n",
    "\n",
    "User defines goal → Agent plans approach → Agent takes actions → Agent evaluates results → Agent adapts and continues → Goal achieved\n",
    "\n",
    "This shift from single-turn to multi-turn, goal-oriented workflows represents a fundamental advancement in how AI systems operate and the problems they can solve.\n",
    "\n",
    "\n",
    "### **LangGraph**: The Framework Behind the Workflow\n",
    "LangGraph is a framework developed by LangChain that allows users to represent Large Language Model (LLM) systems as state machine graphs. This framework provides a simple yet powerful representation that offers a clear workflow for navigating complex tasks.\n",
    "\n",
    "In LangGraph, each node in the graph updates a shared graph state, which is how information is passed from one node to another. The output of the graph is the resulting state once the end node is reached.\n",
    "\n",
    "While there are advanced techniques that allow you to stream elements internally from the graph, we will not be covering those in this example notebook.\n",
    "\n",
    "\n",
    "### Objectives of this Notebook\n",
    "\n",
    "In this notebook, you will:\n",
    "\n",
    "1. Learn how to set up a LangGraph.\n",
    "2. Use an LLM (Large Language Model) to retrieve and summarise information.\n",
    "3. Build an agentic flow that can perform conversational AI requirements, intent design, utterance generation and conversational flow design.\n",
    "\n",
    "This step-by-step guide will help you understand the key components of agentic AI and show you how to construct workflows that can handle complex, adaptive tasks.\n",
    "\n",
    "\n",
    "### The Research Agent Graph Architecture\n",
    "\n",
    "Below is the graph we will be creating in this notebook. This graph represents a conversation design agent with specialised components:\n",
    "\n",
    "1. Requirements Scientist - Analyses business requirements and extracts key needs\n",
    "2. Intent Master - Identifies and categorises core user intents\n",
    "3. Utterance Wizard - Generates diverse training phrases for each intent\n",
    "4. Conversational Artist - Crafts engaging, contextually appropriate responses\n",
    "5. Combiner - Collects all of the team outputs, and combines into a readable format for the user\n",
    "\n",
    "<div style=\"text-align: center; padding:20px;\"> <img src=\"./assets/agenticbasicarchitecture.png\" alt=\"Conversation Design Agent Architecture\" style=\"width: 75%; border-radius: 50px;\"> </div>\n",
    "\n",
    "## The Agent Workflow\n",
    "1. Takes business requirements as input\n",
    "2. Analyses and extracts core user needs and goals\n",
    "3. Identifies key intents users would have when interacting with the system\n",
    "4. Generates diverse ways users might express each intent\n",
    "5. Creates natural, engaging responses for each intent\n",
    "\n",
    "\n",
    "### Let’s get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color: #ffffff;\"><strong>Part 2:</strong></span> Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Activating a Virtual Environment\n",
    "\n",
    "To ensure that all dependencies are installed in an isolated environment, it is recommended to create a virtual environment. Follow the steps below:\n",
    " \n",
    "1. **Create a virtual environment**:\n",
    "\n",
    "> ```bash\n",
    "> uv sync --prerelease=allow\n",
    "> ```\n",
    "\n",
    "This command will create a directory named `.venv` in your current working directory, and it will create a uv.lock file which will track the packages you have installed.\n",
    "\n",
    "2. **Set the notebook kernel to the virtual environment**:\n",
    "\n",
    "To use the virtual environment as the kernel for your Jupyter notebook, follow these steps:\n",
    "\n",
    "> ```bash\n",
    "> uv run python -m ipykernel install --user --name=venv\n",
    "> ```\n",
    "\n",
    "After running the above commands, you can select the `venv` kernel in your Jupyter notebook interface.\n",
    "\n",
    "3. **Set up your Ollama model**:\n",
    "\n",
    "Download the pre-trained model of your choice, we can use TinyLlama for this part as it is lightweight.\n",
    "\n",
    "> ```bash\n",
    "> ollama pull TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
    "> ```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Dependencies\n",
    "\n",
    "The uv sync command has already handled the installation of your dependencies, and you can see them in the pyproject.toml file under the dependencies list. These include the necessary langchain components, ollama and the misc packages for this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up your Ollama model\n",
    "This cell sets up the connection to your Ollama model which will be used for the agentic transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised hf.co/missioner34/Polaris-4B-KentUni.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\" #Replace with the model of your choice (as above in the pull). TinyLlama is a lightweight option.\n",
    "\n",
    "llm = ChatOllama(model=model_name, temperature=0.5)\n",
    "\n",
    "print(f\"Initialised {model_name}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color: #ffffff;\"><strong>Part 3:</strong></span> Building the Agent Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the shared graph state\n",
    "\n",
    "Before diving into the details, let's understand what a graph is in the context of LangGraph. A graph is essentially a structured workflow of interconnected components (nodes) that work together to solve a problem. Each node performs a specific function or task, and the connections between nodes (edges) define how information flows through the system.\n",
    "\n",
    "> **NOTE**: Key points about the graph state object\n",
    "> 1. It's shared across all nodes in the graph.\n",
    "> 2. It serves as a centralised data store for the entire system.\n",
    "> 3. Any information that needs to be passed between nodes must be updated in the state.\n",
    "> 4. Each node can read from and write to the state, allowing for complex information flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, TypedDict\n",
    "\n",
    "class ConversationalAgentState(TypedDict):\n",
    "    input: str  # The initial business requirements from the user\n",
    "    requirements_analysis: str # Output from requirements_scientist_node\n",
    "    intent_model: str  # Output from intent_master_node\n",
    "    utterances: str # Output from utterance_wizard_node\n",
    "    conversational_flows: str  # Output from conversational_artist_node\n",
    "    output: str  # Final combined output\n",
    "    error: Optional[str]  # Error information if any\n",
    "    loop: int  # Counter to prevent infinite recursion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Utils\n",
    "\n",
    "These functions will help to ensure that our LLM JSON responses are properly processed at each stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore as colour\n",
    "import json\n",
    "from typing import Any, Optional\n",
    "\n",
    "def stream_llm_response(prompt: str, \n",
    "                       llm: Any, \n",
    "                       color_code: str = colour.RESET, \n",
    "                       prefix: str = \"\",\n",
    "                       stop_at: Optional[str] = None) -> str:\n",
    "    \"\"\"Stream response from LLM with coloured output.\"\"\"\n",
    "    print(color_code + f\"{prefix}\", end=\"\")\n",
    "    response = \"\"\n",
    "    for chunk in llm.stream(prompt):\n",
    "        chunk_text = chunk.content if hasattr(chunk, \"content\") else str(chunk)\n",
    "        response += chunk_text\n",
    "        print(colour.RESET + chunk_text, end=\"\")\n",
    "        if stop_at and stop_at in chunk_text:\n",
    "            break\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the <span style=\"color: #ffffff;\"><strong>Supervisor</strong></span> Node\n",
    "\n",
    "This function defines the **first node** in our graph. This node is the boss of our flow, and will decide where to go next - it orchestrates between specialists in its\n",
    "\n",
    "> **NOTE**: A `node` is essentially a function that takes the graph state as an input, performs some operations, and updates the state accordingly by returning a dictionary where the `key` matches a variable in the graph state class we defined above. You can think of it analogously as an agent in a team.\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requirements_scientist_node(state: dict):\n",
    "    print(colour.CYAN + \"\\n[Node: Requirements Scientist] Analysing business requirements...\")\n",
    "\n",
    "    input_requirements = state.get(\"input\", \"\")\n",
    "    \n",
    "    prompt = f\"\"\"Analyse these business requirements: {input_requirements}\n",
    "\n",
    "Please provide a clear analysis covering:\n",
    "- Primary goal of the system\n",
    "- Key user needs\n",
    "- Functional requirements\n",
    "- Any constraints or limitations\n",
    "\n",
    "Write your analysis in clear, structured text.\"\"\"\n",
    "\n",
    "    response = stream_llm_response(\n",
    "        prompt=prompt,\n",
    "        llm=llm,\n",
    "        color_code=colour.CYAN,\n",
    "        prefix=\"Analysing Requirements: \"\n",
    "    )\n",
    "    \n",
    "    print(colour.CYAN + \"\\n✓ Requirements analysis complete!\")\n",
    "    return {\"requirements_analysis\": response, \"loop\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the <span style=\"color: #ffffff;\"><strong>Requirements Scientist</strong></span> Node\n",
    "\n",
    "This function defines the **first node** in our graph. This node is where we will be **generating requirements based on the user input** that will be used by later nodes to retrieve information.\n",
    "\n",
    "> **NOTE**: A `node` is essentially a function that takes the graph state as an input, performs some operations, and updates the state accordingly by returning a dictionary where the `key` matches a variable in the graph state class we defined above. You can think of it analogously as an agent in a team.\n",
    "> \n",
    "> In this case, the `requirements_scientist` node uses the user input from the graph state, and returns a set of generated search queries based on this input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requirements_scientist_node(state: dict):\n",
    "    print(colour.CYAN + \"\\n[Node: Requirements Scientist] Analysing business requirements...\")\n",
    "\n",
    "    input_requirements = state.get(\"input\", \"\")\n",
    "    \n",
    "    prompt = f\"\"\"Analyse these business requirements: {input_requirements}\n",
    "\n",
    "Please provide a clear analysis covering:\n",
    "- Primary goal of the system\n",
    "- Key user needs\n",
    "- Functional requirements\n",
    "- Any constraints or limitations\n",
    "\n",
    "Write your analysis in clear, structured text.\"\"\"\n",
    "\n",
    "    response = stream_llm_response(\n",
    "        prompt=prompt,\n",
    "        llm=llm,\n",
    "        color_code=colour.CYAN,\n",
    "        prefix=\"Analysing Requirements: \"\n",
    "    )\n",
    "    \n",
    "    print(colour.CYAN + \"\\n✓ Requirements analysis complete!\")\n",
    "    return {\"requirements_analysis\": response, \"loop\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the <span style=\"color: #ffffff;\"><strong>Intent Master</strong></span> Node\n",
    "\n",
    "This node is responsible for taking the requirements generated by the requirements scientist, and creating an intent model based on that. The intent model is then stored in the graph state to be accessed by subsequent nodes (agents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intent_master_node(state: dict):\n",
    "    print(colour.BLUE + \"\\n[Node: Intent Master] Generating intent model...\")\n",
    "\n",
    "    requirements = state.get(\"requirements_analysis\", \"\")\n",
    "    \n",
    "    prompt = f\"\"\"Based on these requirements:\n",
    "{requirements}\n",
    "\n",
    "Identify the key intents (user goals) for this conversational AI system. For each intent, describe:\n",
    "- Intent name\n",
    "- What the user is trying to accomplish\n",
    "- Why this intent is important\n",
    "\n",
    "Write your response as a clear list of intents with descriptions.\"\"\"\n",
    "\n",
    "    response = stream_llm_response(\n",
    "        prompt=prompt,\n",
    "        llm=llm,\n",
    "        color_code=colour.BLUE,\n",
    "        prefix=\"Generating Intents: \"\n",
    "    )\n",
    "    \n",
    "    print(colour.BLUE + \"\\n✓ Intent model generation complete!\")\n",
    "    return {\"intent_model\": response, \"loop\": state.get(\"loop\", 0) + 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the <span style=\"color: #ffffff;\"><strong>Utterance Wizard</strong></span> Node\n",
    "\n",
    "This node is responsible for creating example utterances for each intent in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utterance_wizard_node(state: dict):\n",
    "    print(colour.YELLOW + \"\\n[Node: Utterance Wizard] Generating example utterances...\")\n",
    "\n",
    "    intent_model = state.get(\"intent_model\", \"\")\n",
    "    \n",
    "    if not intent_model:\n",
    "        error_msg = \"Error: No intent model found in state\"\n",
    "        print(colour.RED + f\"\\n{error_msg}\")\n",
    "        return {\"error\": error_msg, \"loop\": state.get(\"loop\", 0) + 1}\n",
    "    \n",
    "    prompt = f\"\"\"Based on this intent model:\n",
    "{intent_model}\n",
    "\n",
    "Generate 5 example utterances for each intent. Show how users might naturally express each intent in different ways.\n",
    "\n",
    "Make the utterances:\n",
    "- Natural and conversational\n",
    "- Varied in length and style\n",
    "- Representative of real user speech\n",
    "- Include some casual language\n",
    "\n",
    "Format as a clear list for each intent.\"\"\"\n",
    "\n",
    "    response = stream_llm_response(\n",
    "        prompt=prompt,\n",
    "        llm=llm,\n",
    "        color_code=colour.YELLOW,\n",
    "        prefix=\"Generating Utterances: \"\n",
    "    )\n",
    "    \n",
    "    print(colour.YELLOW + \"\\n✓ Utterance generation complete!\")\n",
    "    return {\"utterances\": response, \"loop\": state.get(\"loop\", 0) + 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the <span style=\"color: #ffffff;\"><strong>Conversational Artist</strong></span> Node\n",
    "\n",
    "This node is responsible for creating conversational flow examples based on our requirements, intents and utterances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversational_artist_node(state: dict):\n",
    "    print(colour.MAGENTA + \"\\n[Node: Conversational Artist] Creating conversational flows...\")\n",
    "\n",
    "    utterances = state.get(\"utterances\", \"\")\n",
    "    \n",
    "    if not utterances:\n",
    "        error_msg = \"Error: No utterances found in state\"\n",
    "        print(colour.RED + f\"\\n{error_msg}\")\n",
    "        return {\"error\": error_msg, \"loop\": state.get(\"loop\", 0) + 1}\n",
    "    \n",
    "    prompt = f\"\"\"Based on these utterance examples:\n",
    "{utterances}\n",
    "\n",
    "Create sample conversations showing how a bot should respond to each type of user input.\n",
    "\n",
    "For each intent, show:\n",
    "- User says something (from the utterances)\n",
    "- Bot responds helpfully\n",
    "- User might ask a follow-up\n",
    "- Bot provides more detail\n",
    "\n",
    "Make the bot sound helpful, friendly, and natural. Keep responses concise but informative.\"\"\"\n",
    "\n",
    "    response = stream_llm_response(\n",
    "        prompt=prompt,\n",
    "        llm=llm,\n",
    "        color_code=colour.MAGENTA,\n",
    "        prefix=\"Generating Conversational Flows: \"\n",
    "    )\n",
    "    \n",
    "    print(colour.MAGENTA + \"\\n✓ Conversational flows generation complete!\")\n",
    "    return {\"conversational_flows\": response, \"loop\": state.get(\"loop\", 0) + 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the <span style=\"color: #ffffff;\"><strong>Combiner</strong></span> Node\n",
    "\n",
    "Once we have verified that we have collected enough information to answer the user's question, the **combiner node** combines our requirements, intents, utterances and conversational designs into a readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combiner_node(state: dict):\n",
    "    print(colour.MAGENTA + \"\\n[Node: Combiner] Creating final conversational design document...\")\n",
    "\n",
    "    # Extract all the text inputs\n",
    "    input_requirements = state.get(\"input\", \"\")\n",
    "    requirements_analysis = state.get(\"requirements_analysis\", \"\")\n",
    "    intent_model = state.get(\"intent_model\", \"\")\n",
    "    utterances = state.get(\"utterances\", \"\")\n",
    "    conversational_flows = state.get(\"conversational_flows\", \"\")\n",
    "    error = state.get(\"error\", \"\")\n",
    "\n",
    "    if error:\n",
    "        print(colour.RED + f\"\\nPrevious error detected: {error}\")\n",
    "        print(colour.RED + \"Proceeding with available data...\\n\")\n",
    "\n",
    "    prompt = f\"\"\"Create a well-structured conversation design document combining all these elements:\n",
    "\n",
    "ORIGINAL REQUIREMENTS:\n",
    "{input_requirements}\n",
    "\n",
    "REQUIREMENTS ANALYSIS:\n",
    "{requirements_analysis}\n",
    "\n",
    "INTENT MODEL:\n",
    "{intent_model}\n",
    "\n",
    "UTTERANCE EXAMPLES:\n",
    "{utterances}\n",
    "\n",
    "CONVERSATION FLOWS:\n",
    "{conversational_flows}\n",
    "\n",
    "Format this as a professional document with clear sections:\n",
    "1. Executive Summary\n",
    "2. Conversation Design Overview  \n",
    "3. Intent Structure\n",
    "4. Sample Conversations\n",
    "5. Implementation Recommendations\n",
    "\n",
    "Make it comprehensive and ready to present to stakeholders.\"\"\"\n",
    "\n",
    "    response = stream_llm_response(\n",
    "        prompt=prompt,\n",
    "        llm=llm,\n",
    "        color_code=colour.MAGENTA,\n",
    "        prefix=\"Creating Final Document: \"\n",
    "    )\n",
    "    \n",
    "    print(colour.MAGENTA + \"\\n✓ Conversation design document complete!\")\n",
    "    return {\"output\": response, \"loop\": state.get(\"loop\", 0) + 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing the Agent Graph\n",
    "\n",
    "Finally, after defining each of our graphs' nodes, we can construct the graph by adding each node to the graph object.\n",
    "\n",
    "Here we are arranging our nodes and defining their relationship to one another.\n",
    "\n",
    "Below is a reminder of our architecture:\n",
    "\n",
    "<div style=\"text-align: center; padding:20px;\">\n",
    "    <img src=\"./assets/agenticbasicarchitecture.png\" alt=\"Conversational Design Agent Graph Architecture\" style=\"width: 75%; border-radius: 50px;\">\n",
    "</div>\n",
    "\n",
    "> **NOTE**: \n",
    "> - The solid arrows between the nodes on the graphs are `edges`. These represent one-way connections between two nodes, indicating the flow from one node to another.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Instantiate the graph object with our updated state class\n",
    "graph = StateGraph(ConversationalAgentState)\n",
    "\n",
    "# Add the nodes we have created previously, providing a name string for each\n",
    "graph.add_node(node=\"requirements_scientist\", action=requirements_scientist_node)\n",
    "graph.add_node(node=\"intent_master\", action=intent_master_node)\n",
    "graph.add_node(node=\"utterance_wizard\", action=utterance_wizard_node)\n",
    "graph.add_node(node=\"conversational_artist\", action=conversational_artist_node)\n",
    "graph.add_node(node=\"combiner\", action=combiner_node)\n",
    "\n",
    "# The edges remain the same\n",
    "graph.add_edge(START, \"requirements_scientist\")\n",
    "graph.add_edge(\"requirements_scientist\", \"intent_master\")\n",
    "graph.add_edge(\"intent_master\", \"utterance_wizard\")\n",
    "graph.add_edge(\"utterance_wizard\", \"conversational_artist\")\n",
    "graph.add_edge(\"conversational_artist\", \"combiner\")\n",
    "graph.add_edge(\"combiner\", END)\n",
    "\n",
    "# Compile the graph\n",
    "graph = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have successfully built the research agent graph. In the next section, we will run the graph and see how it performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color: #ffffff;\"><strong>Part 4:</strong></span> Running the Agent Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input a query\n",
    "\n",
    "This is the query you want the Conversational Agent to create requirements, intents, utterances and conversational designs for. Feel free to change the query to test the agent's capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Generate a basic flow for a chatbot that can answer questions about the weather.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Run the Graph\n",
    "\n",
    "The **running the graph** cell is where the research agent’s entire **workflow** is executed, demonstrating how the agent navigates through the graph to answer the user's query.\n",
    "\n",
    "The graph returns the final state of the system, which includes the summarised information that the agent has collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\n",
      "[Node: Requirements Scientist] Analysing business requirements...\n",
      "\u001b[36mAnalysing Requirements: \u001b[39m<think>\u001b[39m\n",
      "\n",
      "\u001b[39m</think>\u001b[39m\n",
      "\n",
      "\u001b[39m**\u001b[39mAnalysis\u001b[39m of\u001b[39m Business\u001b[39m Requirements\u001b[39m:\u001b[39m Chat\u001b[39mbot\u001b[39m for\u001b[39m Weather\u001b[39m Information\u001b[39m**\n",
      "\n",
      "\u001b[39m**\u001b[39mPrimary\u001b[39m Goal\u001b[39m of\u001b[39m the\u001b[39m System\u001b[39m**\u001b[39m  \n",
      "\u001b[39mThe\u001b[39m primary\u001b[39m goal\u001b[39m of\u001b[39m the\u001b[39m weather\u001b[39m chat\u001b[39mbot\u001b[39m is\u001b[39m to\u001b[39m provide\u001b[39m users\u001b[39m with\u001b[39m accurate\u001b[39m,\u001b[39m real\u001b[39m-time\u001b[39m weather\u001b[39m information\u001b[39m in\u001b[39m a\u001b[39m convers\u001b[39mational\u001b[39m and\u001b[39m user\u001b[39m-friendly\u001b[39m manner\u001b[39m.\u001b[39m This\u001b[39m includes\u001b[39m retrieving\u001b[39m current\u001b[39m weather\u001b[39m conditions\u001b[39m,\u001b[39m forecasts\u001b[39m,\u001b[39m and\u001b[39m relevant\u001b[39m weather\u001b[39m alerts\u001b[39m for\u001b[39m specific\u001b[39m locations\u001b[39m.\n",
      "\n",
      "\u001b[39m**\u001b[39mKey\u001b[39m User\u001b[39m Needs\u001b[39m**\u001b[39m  \n",
      "\u001b[39m1\u001b[39m.\u001b[39m **\u001b[39mInstant\u001b[39m Weather\u001b[39m Information\u001b[39m**:\u001b[39m Users\u001b[39m need\u001b[39m quick\u001b[39m access\u001b[39m to\u001b[39m current\u001b[39m weather\u001b[39m conditions\u001b[39m for\u001b[39m a\u001b[39m specific\u001b[39m location\u001b[39m.\u001b[39m  \n",
      "\u001b[39m2\u001b[39m.\u001b[39m **\u001b[39mLocation\u001b[39m-Based\u001b[39m Accuracy\u001b[39m**:\u001b[39m The\u001b[39m chat\u001b[39mbot\u001b[39m should\u001b[39m be\u001b[39m able\u001b[39m to\u001b[39m fetch\u001b[39m weather\u001b[39m data\u001b[39m based\u001b[39m on\u001b[39m the\u001b[39m user\u001b[39m's\u001b[39m input\u001b[39m of\u001b[39m a\u001b[39m city\u001b[39m,\u001b[39m zip\u001b[39m code\u001b[39m,\u001b[39m or\u001b[39m coordinates\u001b[39m.\u001b[39m  \n",
      "\u001b[39m3\u001b[39m.\u001b[39m **\u001b[39mForecast\u001b[39m and\u001b[39m Alerts\u001b[39m**:\u001b[39m Users\u001b[39m should\u001b[39m be\u001b[39m able\u001b[39m to\u001b[39m request\u001b[39m a\u001b[39m forecast\u001b[39m for\u001b[39m upcoming\u001b[39m days\u001b[39m and\u001b[39m receive\u001b[39m alerts\u001b[39m for\u001b[39m severe\u001b[39m weather\u001b[39m conditions\u001b[39m.\u001b[39m  \n",
      "\u001b[39m4\u001b[39m.\u001b[39m **\u001b[39mUser\u001b[39m-F\u001b[39mriendly\u001b[39m Interaction\u001b[39m**:\u001b[39m The\u001b[39m chat\u001b[39mbot\u001b[39m should\u001b[39m respond\u001b[39m in\u001b[39m natural\u001b[39m,\u001b[39m convers\u001b[39mational\u001b[39m language\u001b[39m without\u001b[39m requiring\u001b[39m users\u001b[39m to\u001b[39m navigate\u001b[39m complex\u001b[39m menus\u001b[39m or\u001b[39m formats\u001b[39m.\u001b[39m  \n",
      "\u001b[39m5\u001b[39m.\u001b[39m **\u001b[39mMult\u001b[39milingual\u001b[39m Support\u001b[39m**:\u001b[39m The\u001b[39m chat\u001b[39mbot\u001b[39m should\u001b[39m support\u001b[39m multiple\u001b[39m languages\u001b[39m to\u001b[39m cater\u001b[39m to\u001b[39m a\u001b[39m diverse\u001b[39m user\u001b[39m base\u001b[39m.\u001b[39m  \n",
      "\u001b[39m6\u001b[39m.\u001b[39m **\u001b[39mData\u001b[39m Source\u001b[39m Integration\u001b[39m**:\u001b[39m The\u001b[39m chat\u001b[39mbot\u001b[39m must\u001b[39m integrate\u001b[39m with\u001b[39m reliable\u001b[39m weather\u001b[39m APIs\u001b[39m (\u001b[39me\u001b[39m.g\u001b[39m.,\u001b[39m Open\u001b[39mWeather\u001b[39mMap\u001b[39m,\u001b[39m Acc\u001b[39mu\u001b[39mWeather\u001b[39m)\u001b[39m to\u001b[39m ensure\u001b[39m up\u001b[39m-to\u001b[39m-date\u001b[39m and\u001b[39m accurate\u001b[39m data\u001b[39m.\u001b[39m  \n",
      "\n",
      "\u001b[39m**\u001b[39mFunctional\u001b[39m Requirements\u001b[39m**\u001b[39m  \n",
      "\u001b[39m1\u001b[39m.\u001b[39m **\u001b[39mWeather\u001b[39m Inquiry\u001b[39m**:\u001b[39m The\u001b[39m chat\u001b[39mbot\u001b[39m should\u001b[39m accept\u001b[39m queries\u001b[39m like\u001b[39m \"\u001b[39mWhat\u001b[39m is\u001b[39m the\u001b[39m weather\u001b[39m in\u001b[39m New\u001b[39m York\u001b[39m?\"\u001b[39m and\u001b[39m provide\u001b[39m a\u001b[39m concise\u001b[39m summary\u001b[39m of\u001b[39m current\u001b[39m conditions\u001b[39m,\u001b[39m temperature\u001b[39m,\u001b[39m humidity\u001b[39m,\u001b[39m wind\u001b[39m speed\u001b[39m,\u001b[39m and\u001b[39m precipitation\u001b[39m.\u001b[39m  \n",
      "\u001b[39m2\u001b[39m.\u001b[39m **\u001b[39mForecast\u001b[39m Request\u001b[39m**:\u001b[39m Users\u001b[39m should\u001b[39m be\u001b[39m able\u001b[39m to\u001b[39m ask\u001b[39m for\u001b[39m a\u001b[39m \u001b[39m3\u001b[39m-day\u001b[39m forecast\u001b[39m,\u001b[39m including\u001b[39m temperature\u001b[39m ranges\u001b[39m,\u001b[39m precipitation\u001b[39m chances\u001b[39m,\u001b[39m and\u001b[39m weather\u001b[39m conditions\u001b[39m for\u001b[39m each\u001b[39m day\u001b[39m.\u001b[39m  \n",
      "\u001b[39m3\u001b[39m.\u001b[39m **\u001b[39mAlert\u001b[39m System\u001b[39m**:\u001b[39m The\u001b[39m chat\u001b[39mbot\u001b[39m should\u001b[39m notify\u001b[39m users\u001b[39m of\u001b[39m severe\u001b[39m weather\u001b[39m alerts\u001b[39m (\u001b[39me\u001b[39m.g\u001b[39m.,\u001b[39m thunder\u001b[39mstorms\u001b[39m,\u001b[39m hurricanes\u001b[39m)\u001b[39m based\u001b[39m on\u001b[39m their\u001b[39m location\u001b[39m and\u001b[39m the\u001b[39m severity\u001b[39m of\u001b[39m the\u001b[39m event\u001b[39m.\u001b[39m  \n",
      "\u001b[39m4\u001b[39m.\u001b[39m **\u001b[39mLocation\u001b[39m Input\u001b[39m Handling\u001b[39m**:\u001b[39m The\u001b[39m chat\u001b[39mbot\u001b[39m must\u001b[39m support\u001b[39m various\u001b[39m location\u001b[39m inputs\u001b[39m,\u001b[39m including\u001b[39m city\u001b[39m names\u001b[39m,\u001b[39m zip\u001b[39m codes\u001b[39m,\u001b[39m and\u001b[39m latitude\u001b[39m/\u001b[39mlongitude\u001b[39m coordinates\u001b[39m.\u001b[39m  \n",
      "\u001b[39m5\u001b[39m.\u001b[39m **\u001b[39mMult\u001b[39milingual\u001b[39m Support\u001b[39m**:\u001b[39m The\u001b[39m chat\u001b[39mbot\u001b[39m should\u001b[39m support\u001b[39m multiple\u001b[39m languages\u001b[39m,\u001b[39m such\u001b[39m the\u001b[39m user\u001b[39m's\u001b[39m preferred\u001b[39m language\u001b[39m setting\u001b[39m,\u001b[39m to\u001b[39m ensure\u001b[39m accessibility\u001b[39m.\u001b[39m  \n",
      "\u001b[39m6\u001b[39m.\u001b[39m **\u001b[39mData\u001b[39m Source\u001b[39m Integration\u001b[39m**:\u001b[39m The\u001b[39m chat\u001b[39mbot\u001b[39m must\u001b[39m connect\u001b[39m to\u001b[39m a\u001b[39m reliable\u001b[39m weather\u001b[39m API\u001b[39m to\u001b[39m fetch\u001b[39m and\u001b[39m update\u001b[39m weather\u001b[39m data\u001b[39m in\u001b[39m real\u001b[39m-time\u001b[39m.\u001b[39m  \n",
      "\u001b[39m7\u001b[39m.\u001b[39m **\u001b[39mUser\u001b[39m Preferences\u001b[39m Management\u001b[39m**:\u001b[39m The\u001b[39m chat\u001b[39mbot\u001b[39m should\u001b[39m allow\u001b[39m users\u001b[39m to\u001b[39m set\u001b[39m preferences\u001b[39m,\u001b[39m such\u001b[39m as\u001b[39m preferred\u001b[39m units\u001b[39m (\u001b[39mmetric\u001b[39m or\u001b[39m imperial\u001b[39m),\u001b[39m notification\u001b[39m preferences\u001b[39m,\u001b[39m and\u001b[39m location\u001b[39m tracking\u001b[39m.\u001b[39m  \n",
      "\n",
      "\u001b[39m**\u001b[39mConstraints\u001b[39m and\u001b[39m Limit\u001b[39mations\u001b[39m**\u001b[39m  \n",
      "\u001b[39m1\u001b[39m.\u001b[39m **\u001b[39mAPI\u001b[39m Usage\u001b[39m Limits\u001b[39m**:\u001b[39m The\u001b[39m chat\u001b[39mbot\u001b[39m may\u001b[39m be\u001b[39m subject\u001b[39m to\u001b[39m API\u001b[39m usage\u001b[39m limits\u001b[39m,\u001b[39m requiring\u001b[39m careful\u001b[39m management\u001b[39m of\u001b[39m requests\u001b[39m to\u001b[39m avoid\u001b[39m exceeding\u001b[39m quotas\u001b[39m.\u001b[39m  \n",
      "\u001b[39m2\u001b[39m.\u001b[39m **\u001b[39mAccuracy\u001b[39m of\u001b[39m Data\u001b[39m**:\u001b[39m The\u001b[39m chat\u001b[39mbot\u001b[39m's\u001b[39m reliability\u001b[39m depends\u001b[39m on\u001b[39m the\u001b[39m accuracy\u001b[39m and\u001b[39m tim\u001b[39meliness\u001b[39m of\u001b[39m the\u001b[39m weather\u001b[39m API\u001b[39m it\u001b[39m uses\u001b[39m.\u001b[39m  \n",
      "\u001b[39m3\u001b[39m.\u001b[39m **\u001b[39mLanguage\u001b[39m Support\u001b[39m Scope\u001b[39m**:\u001b[39m While\u001b[39m the\u001b[39m chat\u001b[39mbot\u001b[39m supports\u001b[39m multiple\u001b[39m languages\u001b[39m,\u001b[39m the\u001b[39m extent\u001b[39m of\u001b[39m language\u001b[39m support\u001b[39m depends\u001b[39m on\u001b[39m the\u001b[39m APIs\u001b[39m and\u001b[39m translation\u001b[39m tools\u001b[39m available\u001b[39m.\u001b[39m  \n",
      "\u001b[39m4\u001b[39m.\u001b[39m **\u001b[39mGe\u001b[39mographic\u001b[39m Coverage\u001b[39m**:\u001b[39m The\u001b[39m chat\u001b[39mbot\u001b[39m may\u001b[39m not\u001b[39m provide\u001b[39m weather\u001b[39m information\u001b[39m for\u001b[39m locations\u001b[39m outside\u001b[39m the\u001b[39m API\u001b[39m's\u001b[39m geographic\u001b[39m coverage\u001b[39m.\u001b[39m  \n",
      "\u001b[39m5\u001b[39m.\u001b[39m **\u001b[39mData\u001b[39m Privacy\u001b[39m**:\u001b[39m The\u001b[39m chat\u001b[39mbot\u001b[39m must\u001b[39m comply\u001b[39m with\u001b[39m data\u001b[39m privacy\u001b[39m regulations\u001b[39m (\u001b[39me\u001b[39m.g\u001b[39m.,\u001b[39m GDPR\u001b[39m)\u001b[39m when\u001b[39m collecting\u001b[39m and\u001b[39m storing\u001b[39m user\u001b[39m preferences\u001b[39m and\u001b[39m location\u001b[39m data\u001b[39m.\u001b[39m  \n",
      "\u001b[39m6\u001b[39m.\u001b[39m **\u001b[39mSc\u001b[39mal\u001b[39mability\u001b[39m**:\u001b[39m The\u001b[39m chat\u001b[39mbot\u001b[39m must\u001b[39m be\u001b[39m designed\u001b[39m to\u001b[39m handle\u001b[39m a\u001b[39m growing\u001b[39m user\u001b[39m base\u001b[39m and\u001b[39m increasing\u001b[39m API\u001b[39m requests\u001b[39m without\u001b[39m performance\u001b[39m degradation\u001b[39m.\u001b[39m  \n",
      "\u001b[39m7\u001b[39m.\u001b[39m **\u001b[39mUser\u001b[39m Experience\u001b[39m Cons\u001b[39mistency\u001b[39m**:\u001b[39m Maint\u001b[39maining\u001b[39m a\u001b[39m consistent\u001b[39m and\u001b[39m intuitive\u001b[39m interface\u001b[39m across\u001b[39m different\u001b[39m devices\u001b[39m and\u001b[39m platforms\u001b[39m (\u001b[39me\u001b[39m.g\u001b[39m.,\u001b[39m web\u001b[39m,\u001b[39m mobile\u001b[39m,\u001b[39m desktop\u001b[39m)\u001b[39m is\u001b[39m essential\u001b[39m for\u001b[39m user\u001b[39m satisfaction\u001b[39m.\u001b[39m  \n",
      "\n",
      "\u001b[39m**\u001b[39mConclusion\u001b[39m**\u001b[39m  \n",
      "\u001b[39mThe\u001b[39m weather\u001b[39m chat\u001b[39mbot\u001b[39m system\u001b[39m aims\u001b[39m to\u001b[39m deliver\u001b[39m real\u001b[39m-time\u001b[39m,\u001b[39m accurate\u001b[39m,\u001b[39m and\u001b[39m user\u001b[39m-friendly\u001b[39m weather\u001b[39m information\u001b[39m by\u001b[39m integrating\u001b[39m with\u001b[39m reliable\u001b[39m APIs\u001b[39m and\u001b[39m supporting\u001b[39m multiple\u001b[39m languages\u001b[39m and\u001b[39m location\u001b[39m inputs\u001b[39m.\u001b[39m While\u001b[39m the\u001b[39m system\u001b[39m is\u001b[39m designed\u001b[39m to\u001b[39m be\u001b[39m scalable\u001b[39m and\u001b[39m adaptable\u001b[39m,\u001b[39m it\u001b[39m is\u001b[39m constrained\u001b[39m by\u001b[39m API\u001b[39m usage\u001b[39m limits\u001b[39m,\u001b[39m geographic\u001b[39m coverage\u001b[39m,\u001b[39m and\u001b[39m data\u001b[39m privacy\u001b[39m regulations\u001b[39m.\u001b[39m Success\u001b[39m depends\u001b[39m on\u001b[39m maintaining\u001b[39m high\u001b[39m accuracy\u001b[39m,\u001b[39m responsiveness\u001b[39m,\u001b[39m and\u001b[39m user\u001b[39m satisfaction\u001b[39m while\u001b[39m adher\u001b[39ming\u001b[39m to\u001b[39m technical\u001b[39m and\u001b[39m regulatory\u001b[39m constraints\u001b[39m.\u001b[39m\u001b[39m\u001b[36m\n",
      "✓ Requirements analysis complete!\n",
      "\u001b[34m\n",
      "[Node: Intent Master] Generating intent model...\n",
      "\u001b[34mGenerating Intents: \u001b[39m<think>\u001b[39m\n",
      "\u001b[39mOkay\u001b[39m,\u001b[39m I\u001b[39m need\u001b[39m to\u001b[39m figure\u001b[39m out\u001b[39m the\u001b[39m key\u001b[39m intents\u001b[39m for\u001b[39m the\u001b[39m weather\u001b[39m chat\u001b[39mbot\u001b[39m based\u001b[39m on\u001b[39m the\u001b[39m user\u001b[39m requirements\u001b[39m.\u001b[39m Let\u001b[39m me\u001b[39m start\u001b[39m by\u001b[39m recalling\u001b[39m the\u001b[39m main\u001b[39m goals\u001b[39m mentioned\u001b[39m earlier\u001b[39m.\u001b[39m The\u001b[39m primary\u001b[39m goal\u001b[39m is\u001b[39m to\u001b[39m provide\u001b[39m accurate\u001b[39m,\u001b[39m real\u001b[39m-time\u001b[39m weather\u001b[39m information\u001b[39m through\u001b[39m a\u001b[39m convers\u001b[39mational\u001b[39m interface\u001b[39m.\u001b[39m The\u001b[39m user\u001b[39m needs\u001b[39m to\u001b[39m ask\u001b[39m for\u001b[39m current\u001b[39m weather\u001b[39m,\u001b[39m forecasts\u001b[39m,\u001b[39m alerts\u001b[39m,\u001b[39m and\u001b[39m handle\u001b[39m location\u001b[39m inputs\u001b[39m.\n",
      "\n",
      "\u001b[39mFirst\u001b[39m,\u001b[39m the\u001b[39m main\u001b[39m intent\u001b[39m would\u001b[39m be\u001b[39m asking\u001b[39m for\u001b[39m current\u001b[39m weather\u001b[39m conditions\u001b[39m.\u001b[39m That\u001b[39m's\u001b[39m the\u001b[39m most\u001b[39m basic\u001b[39m query\u001b[39m.\u001b[39m Then\u001b[39m there\u001b[39m's\u001b[39m the\u001b[39m intent\u001b[39m for\u001b[39m requesting\u001b[39m a\u001b[39m forecast\u001b[39m,\u001b[39m which\u001b[39m is\u001b[39m about\u001b[39m future\u001b[39m weather\u001b[39m.\u001b[39m Alerts\u001b[39m are\u001b[39m another\u001b[39m important\u001b[39m intent\u001b[39m since\u001b[39m users\u001b[39m might\u001b[39m need\u001b[39m warnings\u001b[39m about\u001b[39m severe\u001b[39m weather\u001b[39m.\u001b[39m Location\u001b[39m input\u001b[39m is\u001b[39m crucial\u001b[39m because\u001b[39m the\u001b[39m chat\u001b[39mbot\u001b[39m needs\u001b[39m to\u001b[39m know\u001b[39m where\u001b[39m the\u001b[39m user\u001b[39m is\u001b[39m asking\u001b[39m about\u001b[39m the\u001b[39m weather\u001b[39m.\u001b[39m Also\u001b[39m,\u001b[39m the\u001b[39m chat\u001b[39mbot\u001b[39m should\u001b[39m handle\u001b[39m user\u001b[39m preferences\u001b[39m like\u001b[39m units\u001b[39m (\u001b[39mmetric\u001b[39m/im\u001b[39mperial\u001b[39m)\u001b[39m and\u001b[39m language\u001b[39m settings\u001b[39m.\u001b[39m Maybe\u001b[39m there\u001b[39m's\u001b[39m an\u001b[39m intent\u001b[39m for\u001b[39m setting\u001b[39m preferences\u001b[39m.\u001b[39m Oh\u001b[39m,\u001b[39m and\u001b[39m maybe\u001b[39m handling\u001b[39m errors\u001b[39m or\u001b[39m clar\u001b[39mifying\u001b[39m ambiguous\u001b[39m questions\u001b[39m,\u001b[39m like\u001b[39m when\u001b[39m the\u001b[39m user\u001b[39m provides\u001b[39m an\u001b[39m unclear\u001b[39m location\u001b[39m.\u001b[39m Wait\u001b[39m,\u001b[39m the\u001b[39m user\u001b[39m requirements\u001b[39m mention\u001b[39m handling\u001b[39m location\u001b[39m inputs\u001b[39m,\u001b[39m so\u001b[39m maybe\u001b[39m that\u001b[39m's\u001b[39m part\u001b[39m of\u001b[39m the\u001b[39m intent\u001b[39m.\u001b[39m Let\u001b[39m me\u001b[39m structure\u001b[39m this\u001b[39m properly\u001b[39m.\n",
      "\n",
      "\u001b[39mIntent\u001b[39m \u001b[39m1\u001b[39m:\u001b[39m Current\u001b[39m Weather\u001b[39m Inquiry\u001b[39m.\u001b[39m The\u001b[39m user\u001b[39m wants\u001b[39m the\u001b[39m current\u001b[39m weather\u001b[39m for\u001b[39m a\u001b[39m specific\u001b[39m location\u001b[39m.\u001b[39m Important\u001b[39m because\u001b[39m it\u001b[39m's\u001b[39m the\u001b[39m primary\u001b[39m function\u001b[39m of\u001b[39m the\u001b[39m chat\u001b[39mbot\u001b[39m.\u001b[39m Intent\u001b[39m \u001b[39m2\u001b[39m:\u001b[39m Weather\u001b[39m Forecast\u001b[39m Request\u001b[39m.\u001b[39m The\u001b[39m user\u001b[39m asks\u001b[39m for\u001b[39m a\u001b[39m forecast\u001b[39m,\u001b[39m which\u001b[39m helps\u001b[39m them\u001b[39m plan\u001b[39m for\u001b[39m upcoming\u001b[39m days\u001b[39m.\u001b[39m Intent\u001b[39m \u001b[39m3\u001b[39m:\u001b[39m Weather\u001b[39m Alerts\u001b[39m.\u001b[39m Users\u001b[39m need\u001b[39m warnings\u001b[39m about\u001b[39m severe\u001b[39m weather\u001b[39m,\u001b[39m so\u001b[39m this\u001b[39m intent\u001b[39m ensures\u001b[39m they\u001b[39m're\u001b[39m informed\u001b[39m about\u001b[39m potential\u001b[39m dangers\u001b[39m.\u001b[39m Intent\u001b[39m \u001b[39m4\u001b[39m:\u001b[39m Location\u001b[39m Input\u001b[39m.\u001b[39m The\u001b[39m chat\u001b[39mbot\u001b[39m must\u001b[39m process\u001b[39m different\u001b[39m ways\u001b[39m users\u001b[39m provide\u001b[39m location\u001b[39m details\u001b[39m.\u001b[39m Intent\u001b[39m \u001b[39m5\u001b[39m:\u001b[39m User\u001b[39m Preferences\u001b[39m.\u001b[39m Managing\u001b[39m units\u001b[39m and\u001b[39m language\u001b[39m settings\u001b[39m to\u001b[39m personalize\u001b[39m the\u001b[39m experience\u001b[39m.\u001b[39m Intent\u001b[39m \u001b[39m6\u001b[39m:\u001b[39m Error\u001b[39m Handling\u001b[39m.\u001b[39m When\u001b[39m the\u001b[39m user\u001b[39m's\u001b[39m input\u001b[39m is\u001b[39m unclear\u001b[39m or\u001b[39m invalid\u001b[39m,\u001b[39m the\u001b[39m chat\u001b[39mbot\u001b[39m needs\u001b[39m to\u001b[39m ask\u001b[39m for\u001b[39m clarification\u001b[39m.\u001b[39m Intent\u001b[39m \u001b[39m7\u001b[39m:\u001b[39m Location\u001b[39m-Based\u001b[39m Weather\u001b[39m.\u001b[39m Ens\u001b[39muring\u001b[39m the\u001b[39m chat\u001b[39mbot\u001b[39m can\u001b[39m fetch\u001b[39m data\u001b[39m based\u001b[39m on\u001b[39m the\u001b[39m user\u001b[39m's\u001b[39m location\u001b[39m,\u001b[39m maybe\u001b[39m even\u001b[39m tracking\u001b[39m their\u001b[39m current\u001b[39m location\u001b[39m if\u001b[39m available\u001b[39m.\u001b[39m Wait\u001b[39m,\u001b[39m the\u001b[39m user\u001b[39m requirements\u001b[39m mention\u001b[39m handling\u001b[39m location\u001b[39m inputs\u001b[39m,\u001b[39m so\u001b[39m maybe\u001b[39m that\u001b[39m's\u001b[39m part\u001b[39m of\u001b[39m the\u001b[39m intent\u001b[39m.\u001b[39m Hmm\u001b[39m,\u001b[39m I\u001b[39m need\u001b[39m to\u001b[39m make\u001b[39m sure\u001b[39m each\u001b[39m intent\u001b[39m is\u001b[39m distinct\u001b[39m and\u001b[39m covers\u001b[39m the\u001b[39m user\u001b[39m's\u001b[39m goals\u001b[39m.\u001b[39m Let\u001b[39m me\u001b[39m check\u001b[39m again\u001b[39m.\u001b[39m The\u001b[39m user\u001b[39m wants\u001b[39m to\u001b[39m ask\u001b[39m for\u001b[39m current\u001b[39m weather\u001b[39m,\u001b[39m forecast\u001b[39m,\u001b[39m alerts\u001b[39m,\u001b[39m handle\u001b[39m location\u001b[39m inputs\u001b[39m,\u001b[39m set\u001b[39m preferences\u001b[39m,\u001b[39m and\u001b[39m manage\u001b[39m errors\u001b[39m.\u001b[39m That\u001b[39m seems\u001b[39m comprehensive\u001b[39m.\u001b[39m I\u001b[39m think\u001b[39m that\u001b[39m's\u001b[39m all\u001b[39m the\u001b[39m key\u001b[39m intents\u001b[39m.\n",
      "\u001b[39m</think>\u001b[39m\n",
      "\n",
      "\u001b[39m**\u001b[39mKey\u001b[39m Int\u001b[39ments\u001b[39m for\u001b[39m the\u001b[39m Weather\u001b[39m Chat\u001b[39mbot\u001b[39m**\u001b[39m  \n",
      "\n",
      "\u001b[39m1\u001b[39m.\u001b[39m **\u001b[39mCurrent\u001b[39m Weather\u001b[39m Inquiry\u001b[39m**\u001b[39m  \n",
      "\u001b[39m  \u001b[39m -\u001b[39m **\u001b[39mWhat\u001b[39m the\u001b[39m user\u001b[39m is\u001b[39m trying\u001b[39m to\u001b[39m accomplish\u001b[39m**:\u001b[39m Request\u001b[39m real\u001b[39m-time\u001b[39m weather\u001b[39m conditions\u001b[39m (\u001b[39mtemperature\u001b[39m,\u001b[39m humidity\u001b[39m,\u001b[39m wind\u001b[39m,\u001b[39m precipitation\u001b[39m)\u001b[39m for\u001b[39m a\u001b[39m specific\u001b[39m location\u001b[39m.\u001b[39m  \n",
      "\u001b[39m  \u001b[39m -\u001b[39m **\u001b[39mWhy\u001b[39m this\u001b[39m intent\u001b[39m is\u001b[39m important\u001b[39m**:\u001b[39m This\u001b[39m is\u001b[39m the\u001b[39m primary\u001b[39m function\u001b[39m of\u001b[39m the\u001b[39m chat\u001b[39mbot\u001b[39m,\u001b[39m providing\u001b[39m immediate\u001b[39m,\u001b[39m actionable\u001b[39m weather\u001b[39m data\u001b[39m to\u001b[39m help\u001b[39m users\u001b[39m make\u001b[39m decisions\u001b[39m (\u001b[39me\u001b[39m.g\u001b[39m.,\u001b[39m whether\u001b[39m to\u001b[39m carry\u001b[39m an\u001b[39m umbrella\u001b[39m or\u001b[39m wear\u001b[39m a\u001b[39m jacket\u001b[39m).\u001b[39m  \n",
      "\n",
      "\u001b[39m2\u001b[39m.\u001b[39m **\u001b[39mWeather\u001b[39m Forecast\u001b[39m Request\u001b[39m**\u001b[39m  \n",
      "\u001b[39m  \u001b[39m -\u001b[39m **\u001b[39mWhat\u001b[39m the\u001b[39m user\u001b[39m is\u001b[39m trying\u001b[39m to\u001b[39m accomplish\u001b[39m**:\u001b[39m Ask\u001b[39m for\u001b[39m a\u001b[39m \u001b[39m3\u001b[39m-day\u001b[39m forecast\u001b[39m or\u001b[39m extended\u001b[39m forecast\u001b[39m (\u001b[39me\u001b[39m.g\u001b[39m.,\u001b[39m \"\u001b[39mWhat\u001b[39m will\u001b[39m the\u001b[39m weather\u001b[39m be\u001b[39m like\u001b[39m for\u001b[39m the\u001b[39m next\u001b[39m \u001b[39m5\u001b[39m days\u001b[39m?\u001b[39m\").\u001b[39m  \n",
      "\u001b[39m  \u001b[39m -\u001b[39m **\u001b[39mWhy\u001b[39m this\u001b[39m intent\u001b[39m is\u001b[39m important\u001b[39m**:\u001b[39m Users\u001b[39m need\u001b[39m long\u001b[39m-term\u001b[39m planning\u001b[39m capabilities\u001b[39m,\u001b[39m such\u001b[39m to\u001b[39m prepare\u001b[39m for\u001b[39m outdoor\u001b[39m activities\u001b[39m,\u001b[39m travel\u001b[39m,\u001b[39m or\u001b[39m seasonal\u001b[39m changes\u001b[39m.\u001b[39m  \n",
      "\n",
      "\u001b[39m3\u001b[39m.\u001b[39m **\u001b[39mWeather\u001b[39m Alerts\u001b[39m**\u001b[39m  \n",
      "\u001b[39m  \u001b[39m -\u001b[39m **\u001b[39mWhat\u001b[39m the\u001b[39m user\u001b[39m is\u001b[39m trying\u001b[39m to\u001b[39m accomplish\u001b[39m**:\u001b[39m Request\u001b[39m or\u001b[39m receive\u001b[39m alerts\u001b[39m for\u001b[39m severe\u001b[39m weather\u001b[39m (\u001b[39me\u001b[39m.g\u001b[39m.,\u001b[39m thunder\u001b[39mstorms\u001b[39m,\u001b[39m hurricanes\u001b[39m,\u001b[39m heat\u001b[39mwaves\u001b[39m).\u001b[39m  \n",
      "\u001b[39m  \u001b[39m -\u001b[39m **\u001b[39mWhy\u001b[39m this\u001b[39m intent\u001b[39m is\u001b[39m important\u001b[39m**:\u001b[39m This\u001b[39m ensures\u001b[39m users\u001b[39m are\u001b[39m informed\u001b[39m about\u001b[39m potential\u001b[39m dangers\u001b[39m in\u001b[39m their\u001b[39m area\u001b[39m,\u001b[39m improving\u001b[39m safety\u001b[39m and\u001b[39m prepared\u001b[39mness\u001b[39m.\u001b[39m  \n",
      "\n",
      "\u001b[39m4\u001b[39m.\u001b[39m **\u001b[39mLocation\u001b[39m Input\u001b[39m Handling\u001b[39m**\u001b[39m  \n",
      "\u001b[39m  \u001b[39m -\u001b[39m **\u001b[39mWhat\u001b[39m the\u001b[39m user\u001b[39m is\u001b[39m trying\u001b[39m to\u001b[39m accomplish\u001b[39m**:\u001b[39m Provide\u001b[39m location\u001b[39m details\u001b[39m (\u001b[39mcity\u001b[39m names\u001b[39m,\u001b[39m zip\u001b[39m codes\u001b[39m,\u001b[39m coordinates\u001b[39m)\u001b[39m to\u001b[39m fetch\u001b[39m weather\u001b[39m data\u001b[39m.\u001b[39m  \n",
      "\u001b[39m  \u001b[39m -\u001b[39m **\u001b[39mWhy\u001b[39m this\u001b[39m intent\u001b[39m is\u001b[39m important\u001b[39m**:\u001b[39m Acc\u001b[39murate\u001b[39m location\u001b[39m input\u001b[39m is\u001b[39m critical\u001b[39m for\u001b[39m retrieving\u001b[39m relevant\u001b[39m weather\u001b[39m information\u001b[39m,\u001b[39m especially\u001b[39m for\u001b[39m users\u001b[39m in\u001b[39m different\u001b[39m geographic\u001b[39m regions\u001b[39m.\u001b[39m  \n",
      "\n",
      "\u001b[39m5\u001b[39m.\u001b[39m **\u001b[39mUser\u001b[39m Preferences\u001b[39m Management\u001b[39m**\u001b[39m  \n",
      "\u001b[39m  \u001b[39m -\u001b[39m **\u001b[39mWhat\u001b[39m the\u001b[39m user\u001b[39m is\u001b[39m trying\u001b[39m to\u001b[39m accomplish\u001b[39m**:\u001b[39m Set\u001b[39m or\u001b[39m adjust\u001b[39m preferences\u001b[39m (\u001b[39me\u001b[39m.g\u001b[39m.,\u001b[39m preferred\u001b[39m temperature\u001b[39m units\u001b[39m,\u001b[39m language\u001b[39m,\u001b[39m notification\u001b[39m settings\u001b[39m).\u001b[39m  \n",
      "\u001b[39m  \u001b[39m -\u001b[39m **\u001b[39mWhy\u001b[39m this\u001b[39m intent\u001b[39m is\u001b[39m important\u001b[39m**:\u001b[39m Personal\u001b[39mizing\u001b[39m the\u001b[39m experience\u001b[39m ensures\u001b[39m the\u001b[39m chat\u001b[39mbot\u001b[39m meets\u001b[39m the\u001b[39m user\u001b[39m's\u001b[39m specific\u001b[39m needs\u001b[39m and\u001b[39m preferences\u001b[39m.\u001b[39m  \n",
      "\n",
      "\u001b[39m6\u001b[39m.\u001b[39m **\u001b[39mError\u001b[39m Handling\u001b[39m and\u001b[39m Clar\u001b[39mification\u001b[39m**\u001b[39m  \n",
      "\u001b[39m  \u001b[39m -\u001b[39m **\u001b[39mWhat\u001b[39m the\u001b[39m user\u001b[39m is\u001b[39m trying\u001b[39m to\u001b[39m accomplish\u001b[39m**:\u001b[39m Address\u001b[39m ambiguous\u001b[39m or\u001b[39m invalid\u001b[39m inputs\u001b[39m (\u001b[39me\u001b[39m.g\u001b[39m.,\u001b[39m \"\u001b[39mWhat\u001b[39m is\u001b[39m the\u001b[39m weather\u001b[39m like\u001b[39m in\u001b[39m Paris\u001b[39m?\u001b[39m\").\u001b[39m  \n",
      "\u001b[39m  \u001b[39m -\u001b[39m **\u001b[39mWhy\u001b[39m this\u001b[39m intent\u001b[39m is\u001b[39m important\u001b[39m**:\u001b[39m Ens\u001b[39mures\u001b[39m the\u001b[39m chat\u001b[39mbot\u001b[39m can\u001b[39m handle\u001b[39m unclear\u001b[39m queries\u001b[39m,\u001b[39m ask\u001b[39m for\u001b[39m clarification\u001b[39m,\u001b[39m or\u001b[39m provide\u001b[39m helpful\u001b[39m guidance\u001b[39m when\u001b[39m the\u001b[39m input\u001b[39m is\u001b[39m incomplete\u001b[39m or\u001b[39m incorrect\u001b[39m.\u001b[39m  \n",
      "\n",
      "\u001b[39m7\u001b[39m.\u001b[39m **\u001b[39mLocation\u001b[39m-Based\u001b[39m Weather\u001b[39m (\u001b[39mGe\u001b[39molocation\u001b[39m)**\u001b[39m  \n",
      "\u001b[39m  \u001b[39m -\u001b[39m **\u001b[39mWhat\u001b[39m the\u001b[39m user\u001b[39m is\u001b[39m trying\u001b[39m to\u001b[39m accomplish\u001b[39m**:\u001b[39m Request\u001b[39m weather\u001b[39m data\u001b[39m based\u001b[39m on\u001b[39m the\u001b[39m user\u001b[39m's\u001b[39m current\u001b[39m location\u001b[39m (\u001b[39me\u001b[39m.g\u001b[39m.,\u001b[39m \"\u001b[39mWhat\u001b[39m's\u001b[39m the\u001b[39m weather\u001b[39m like\u001b[39m where\u001b[39m I\u001b[39m am\u001b[39m?\u001b[39m\").\u001b[39m  \n",
      "\u001b[39m  \u001b[39m -\u001b[39m **\u001b[39mWhy\u001b[39m this\u001b[39m intent\u001b[39m is\u001b[39m important\u001b[39m**:\u001b[39m Enables\u001b[39m seamless\u001b[39m,\u001b[39m personalized\u001b[39m weather\u001b[39m updates\u001b[39m without\u001b[39m requiring\u001b[39m users\u001b[39m to\u001b[39m manually\u001b[39m input\u001b[39m their\u001b[39m location\u001b[39m.\u001b[39m  \n",
      "\n",
      "\u001b[39mThese\u001b[39m intents\u001b[39m collectively\u001b[39m ensure\u001b[39m the\u001b[39m chat\u001b[39mbot\u001b[39m is\u001b[39m versatile\u001b[39m,\u001b[39m user\u001b[39m-friendly\u001b[39m,\u001b[39m and\u001b[39m capable\u001b[39m of\u001b[39m addressing\u001b[39m a\u001b[39m wide\u001b[39m range\u001b[39m of\u001b[39m weather\u001b[39m-related\u001b[39m needs\u001b[39m while\u001b[39m maintaining\u001b[39m accuracy\u001b[39m and\u001b[39m reliability\u001b[39m.\u001b[39m\u001b[39m\u001b[34m\n",
      "✓ Intent model generation complete!\n",
      "\u001b[33m\n",
      "[Node: Utterance Wizard] Generating example utterances...\n",
      "\u001b[33mGenerating Utterances: \u001b[39m<think>\u001b[39m\n",
      "\u001b[39mOkay\u001b[39m,\u001b[39m I\u001b[39m need\u001b[39m to\u001b[39m come\u001b[39m up\u001b[39m with\u001b[39m \u001b[39m5\u001b[39m example\u001b[39m utter\u001b[39mances\u001b[39m for\u001b[39m each\u001b[39m of\u001b[39m the\u001b[39m \u001b[39m7\u001b[39m intents\u001b[39m.\u001b[39m Let\u001b[39m me\u001b[39m start\u001b[39m by\u001b[39m recalling\u001b[39m the\u001b[39m intents\u001b[39m and\u001b[39m their\u001b[39m purposes\u001b[39m.\u001b[39m  \n",
      "\n",
      "\u001b[39m**\u001b[39m1\u001b[39m.\u001b[39m Current\u001b[39m Weather\u001b[39m Inquiry\u001b[39m**\u001b[39m  \n",
      "\u001b[39mThe\u001b[39m user\u001b[39m is\u001b[39m asking\u001b[39m for\u001b[39m real\u001b[39m-time\u001b[39m weather\u001b[39m data\u001b[39m.\u001b[39m Examples\u001b[39m should\u001b[39m include\u001b[39m different\u001b[39m ways\u001b[39m to\u001b[39m phrase\u001b[39m \"\u001b[39mwhat\u001b[39m's\u001b[39m the\u001b[39m weather\u001b[39m like\u001b[39m today\u001b[39m?\"\u001b[39m in\u001b[39m various\u001b[39m locations\u001b[39m.\u001b[39m  \n",
      "\n",
      "\u001b[39m**\u001b[39m2\u001b[39m.\u001b[39m Weather\u001b[39m Forecast\u001b[39m Request\u001b[39m**\u001b[39m  \n",
      "\u001b[39mUsers\u001b[39m want\u001b[39m future\u001b[39m weather\u001b[39m predictions\u001b[39m.\u001b[39m Examples\u001b[39m might\u001b[39m include\u001b[39m asking\u001b[39m for\u001b[39m a\u001b[39m \u001b[39m5\u001b[39m-day\u001b[39m forecast\u001b[39m or\u001b[39m specific\u001b[39m days\u001b[39m.\u001b[39m  \n",
      "\n",
      "\u001b[39m**\u001b[39m3\u001b[39m.\u001b[39m Weather\u001b[39m Alerts\u001b[39m**\u001b[39m  \n",
      "\u001b[39mUsers\u001b[39m are\u001b[39m looking\u001b[39m for\u001b[39m severe\u001b[39m weather\u001b[39m warnings\u001b[39m.\u001b[39m Examples\u001b[39m could\u001b[39m be\u001b[39m asking\u001b[39m about\u001b[39m tornado\u001b[39mes\u001b[39m,\u001b[39m hurricanes\u001b[39m,\u001b[39m or\u001b[39m extreme\u001b[39m heat\u001b[39m.\u001b[39m  \n",
      "\n",
      "\u001b[39m**\u001b[39m4\u001b[39m.\u001b[39m Location\u001b[39m Input\u001b[39m Handling\u001b[39m**\u001b[39m  \n",
      "\u001b[39mUsers\u001b[39m provide\u001b[39m location\u001b[39m details\u001b[39m.\u001b[39m Examples\u001b[39m include\u001b[39m city\u001b[39m names\u001b[39m,\u001b[39m zip\u001b[39m codes\u001b[39m,\u001b[39m or\u001b[39m coordinates\u001b[39m.\u001b[39m  \n",
      "\n",
      "\u001b[39m**\u001b[39m5\u001b[39m.\u001b[39m User\u001b[39m Preferences\u001b[39m Management\u001b[39m**\u001b[39m  \n",
      "\u001b[39mUsers\u001b[39m adjust\u001b[39m settings\u001b[39m like\u001b[39m units\u001b[39m or\u001b[39m language\u001b[39m.\u001b[39m Examples\u001b[39m might\u001b[39m be\u001b[39m asking\u001b[39m to\u001b[39m switch\u001b[39m to\u001b[39m Celsius\u001b[39m or\u001b[39m set\u001b[39m preferences\u001b[39m for\u001b[39m notifications\u001b[39m.\u001b[39m  \n",
      "\n",
      "\u001b[39m**\u001b[39m6\u001b[39m.\u001b[39m Error\u001b[39m Handling\u001b[39m and\u001b[39m Clar\u001b[39mification\u001b[39m**\u001b[39m  \n",
      "\u001b[39mUsers\u001b[39m have\u001b[39m unclear\u001b[39m or\u001b[39m invalid\u001b[39m inputs\u001b[39m.\u001b[39m Examples\u001b[39m include\u001b[39m asking\u001b[39m for\u001b[39m clarification\u001b[39m when\u001b[39m the\u001b[39m location\u001b[39m is\u001b[39m ambiguous\u001b[39m.\u001b[39m  \n",
      "\n",
      "\u001b[39m**\u001b[39m7\u001b[39m.\u001b[39m Location\u001b[39m-Based\u001b[39m Weather\u001b[39m (\u001b[39mGe\u001b[39molocation\u001b[39m)**\u001b[39m  \n",
      "\u001b[39mUsers\u001b[39m request\u001b[39m weather\u001b[39m based\u001b[39m on\u001b[39m their\u001b[39m current\u001b[39m location\u001b[39m.\u001b[39m Examples\u001b[39m like\u001b[39m \"\u001b[39mWhat\u001b[39m's\u001b[39m the\u001b[39m weather\u001b[39m like\u001b[39m where\u001b[39m I\u001b[39m am\u001b[39m?\"\u001b[39m or\u001b[39m \"\u001b[39mCheck\u001b[39m my\u001b[39m location\u001b[39m for\u001b[39m weather\u001b[39m.\"\u001b[39m  \n",
      "\n",
      "\u001b[39mNow\u001b[39m,\u001b[39m I\u001b[39m need\u001b[39m to\u001b[39m make\u001b[39m sure\u001b[39m each\u001b[39m example\u001b[39m is\u001b[39m natural\u001b[39m,\u001b[39m varied\u001b[39m,\u001b[39m and\u001b[39m includes\u001b[39m casual\u001b[39m language\u001b[39m.\u001b[39m Let\u001b[39m me\u001b[39m brainstorm\u001b[39m each\u001b[39m intent\u001b[39m one\u001b[39m by\u001b[39m one\u001b[39m,\u001b[39m ensuring\u001b[39m the\u001b[39m examples\u001b[39m are\u001b[39m distinct\u001b[39m and\u001b[39m cover\u001b[39m different\u001b[39m ph\u001b[39mras\u001b[39mings\u001b[39m.\u001b[39m\u001b[39m\u001b[33m\n",
      "✓ Utterance generation complete!\n",
      "\u001b[35m\n",
      "[Node: Conversational Artist] Creating conversational flows...\n",
      "\u001b[35mGenerating Conversational Flows: \u001b[39m<think>\u001b[39m\n",
      "\u001b[39mOkay\u001b[39m,\u001b[39m I\u001b[39m need\u001b[39m to\u001b[39m create\u001b[39m sample\u001b[39m conversations\u001b[39m for\u001b[39m each\u001b[39m of\u001b[39m the\u001b[39m \u001b[39m7\u001b[39m intents\u001b[39m.\u001b[39m Let\u001b[39m me\u001b[39m start\u001b[39m by\u001b[39m recalling\u001b[39m the\u001b[39m user\u001b[39m examples\u001b[39m and\u001b[39m the\u001b[39m bot\u001b[39m's\u001b[39m responses\u001b[39m.\u001b[39m  \n",
      "\n",
      "\u001b[39m**\u001b[39m1\u001b[39m.\u001b[39m Current\u001b[39m Weather\u001b[39m Inquiry\u001b[39m**\u001b[39m  \n",
      "\u001b[39mUser\u001b[39m:\u001b[39m \"\u001b[39mWhat\u001b[39m's\u001b[39m the\u001b[39m weather\u001b[39m like\u001b[39m today\u001b[39m in\u001b[39m New\u001b[39m York\u001b[39m?\"\u001b[39m  \n",
      "\u001b[39mBot\u001b[39m:\u001b[39m \"\u001b[39mIt\u001b[39m's\u001b[39m currently\u001b[39m \u001b[39m7\u001b[39m2\u001b[39m°F\u001b[39m with\u001b[39m partly\u001b[39m cloudy\u001b[39m skies\u001b[39m and\u001b[39m light\u001b[39m rain\u001b[39m expected\u001b[39m by\u001b[39m evening\u001b[39m.\"\u001b[39m  \n",
      "\u001b[39mUser\u001b[39m:\u001b[39m \"\u001b[39mIs\u001b[39m it\u001b[39m going\u001b[39m to\u001b[39m rain\u001b[39m?\"\u001b[39m  \n",
      "\u001b[39mBot\u001b[39m:\u001b[39m \"\u001b[39mYes\u001b[39m,\u001b[39m rain\u001b[39m showers\u001b[39m are\u001b[39m forecast\u001b[39med\u001b[39m for\u001b[39m the\u001b[39m afternoon\u001b[39m.\"\u001b[39m  \n",
      "\n",
      "\u001b[39m**\u001b[39m2\u001b[39m.\u001b[39m Weather\u001b[39m Forecast\u001b[39m Request\u001b[39m**\u001b[39m  \n",
      "\u001b[39mUser\u001b[39m:\u001b[39m \"\u001b[39mCan\u001b[39m you\u001b[39m tell\u001b[39m me\u001b[39m the\u001b[39m \u001b[39m5\u001b[39m-day\u001b[39m forecast\u001b[39m for\u001b[39m Chicago\u001b[39m?\"\u001b[39m  \n",
      "\u001b[39mBot\u001b[39m:\u001b[39m \"\u001b[39mSure\u001b[39m!\u001b[39m Here\u001b[39m's\u001b[39m the\u001b[39m forecast\u001b[39m:\u001b[39m Monday\u001b[39m \u001b[39m6\u001b[39m8\u001b[39m°F\u001b[39m,\u001b[39m partly\u001b[39m cloudy\u001b[39m;\u001b[39m Tuesday\u001b[39m \u001b[39m7\u001b[39m1\u001b[39m°F\u001b[39m,\u001b[39m sunny\u001b[39m;\u001b[39m Wednesday\u001b[39m \u001b[39m7\u001b[39m3\u001b[39m°F\u001b[39m,\u001b[39m light\u001b[39m rain\u001b[39m.\"\u001b[39m  \n",
      "\u001b[39mUser\u001b[39m:\u001b[39m \"\u001b[39mWhat\u001b[39m about\u001b[39m Thursday\u001b[39m?\"\u001b[39m  \n",
      "\u001b[39mBot\u001b[39m:\u001b[39m \"\u001b[39mThursday\u001b[39m will\u001b[39m be\u001b[39m \u001b[39m7\u001b[39m0"
     ]
    }
   ],
   "source": [
    "final_state = graph.invoke({\"input\": user_query})\n",
    "\n",
    "print(colour.WHITE + \"\\n[Final Graph State Output]:\\n\\n\", json.dumps(final_state, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Congratulations! You have successfully built a conversational development agentic flow using LangGraph!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ffffff;\"><strong>Part 5:</strong></span> Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Accomplishments:\n",
    "- Developed a Conversational Project agent using LangGraph in an Agentic AI architecture.\n",
    "- Enabled the agents to generate requirements, intents, utterances and conversational designs.\n",
    "- Demonstrated the use of nodes and graphs to create agentic stages, with edges directing a sequential execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Author: Matthew Sayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ffffff;\"><strong>Optional - Part 6:</strong></span> Continued - Using Microsoft Agent Framework with MCP tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, we will use the Microsoft Agent Framework to create a ChatAgent object.\n",
    "#### This will wrap our Ollama model and execute our MCP tools.\n",
    "##### In this case, we will be running our FizzBuzz tool (to show MCP usage) and then ask the model about the University of Kent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a tool-calling capable model, in this case using a fine-tuned Kent Uni model as covered in the fine tuning notebook.\n",
    "\n",
    ">```bash\n",
    "> ollama pull hf.co/missioner34/Polaris-4B-KentUni\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the imports for Microsoft Agent Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import ChatAgent\n",
    "from agent_framework import WorkflowOutputEvent\n",
    "from agent_framework.openai import OpenAIChatClient #We're using OpenAI client here because this allows us to use our own local model\n",
    "\n",
    "from agent_framework import MCPStreamableHTTPTool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the chat client, which will contain the default Ollama URL and the model ID to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAIChatClient(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    model_id=\"hf.co/missioner34/Polaris-4B-KentUni\",\n",
    "    api_key=\"none\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create our MCP tool instance, then set up our agents to create an article researcher tool. Ensure your MCP server has been started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolset = MCPStreamableHTTPTool(\n",
    "    name=\"mcp_server\",\n",
    "    url=\"http://localhost:8080/mcp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up our agent, which will be called Assistant and use our MCP toolset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_agent = ChatAgent(\n",
    "        chat_client=client,\n",
    "        name=\"Assistant\",\n",
    "        instructions=\"You are helpful and can use MCP tools to answer questions.\",\n",
    "        tools=toolset,\n",
    "    )\n",
    "\n",
    "thread = mcp_agent.get_new_thread() #creates a new conversational thread (a session)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's input the query we want to ask. You can set it to what you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_request = \"\"\"Can you please do a FizzBuzz with the limit as 50, and explain what happened?\n",
    "\n",
    "Can you also please tell me some facts you know about the University of Kent?\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we'll run the stream. For each chunk produced in our output stream, we print the text so you can read it as it is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "<|endoftext|>Okay, the user asked for a FizzBuzz up to 50 and some facts about the University of Kent. Let me start by recalling the FizzBuzz function. The function takes an integer x, which in this case is 50. The output is a dictionary with keys as the numbers from 1 to 50 and values as \"Fizz\", \"Buzz\", \"FizzBuzz\", or the number itself when neither 3 nor 5 divides it. \n",
      "\n",
      "Looking at the response provided, the dictionary shows that for numbers divisible by 3, it's \"Fizz\", by 5 it's \"Buzz\", and by both 3 and 5 (i.e., 15, 30, etc.) it's \"FizzBuzz\". Numbers not divisible by either are kept as they are. The user might be testing the function's correctness, so I should validate that the key-value pairs align with the standard FizzBuzz rules.\n",
      "\n",
      "Next, the University of Kent facts. The user probably wants information about the university's history, campus locations, academic programs, or rankings. Since the assistant's knowledge is up to a certain date, I need to mention that it's based on available data, including establishment year (1965), campus locations in Canterbury and Medway, Business School rankings, and student population. I should also highlight that specific details like rankings and student numbers may change over time. \n",
      "\n",
      "Wait, the user asked about the University of Kent in the same query. The assistant should check if it has access to current data. If not, it should mention that the information is up to its knowledge cutoff. Also, the answer should be concise but informative, covering key points like establishment year, campuses, notable programs, and student numbers. \n",
      "\n",
      "I need to ensure the explanation of FizzBuzz is clear, maybe mention that the function checks divisibility by 3 and 5, and combines them when both conditions are true. For the University of Kent, list the campuses, key strengths in Business, Engineering, and Computer Science, and general student numbers. Also, note that the user should verify the latest data for accuracy.\n",
      "</think>\n",
      "\n",
      "The FizzBuzz calculation up to 50 includes the following results:\n",
      "- **FizzBuzz Rules**:  \n",
      "  - Numbers divisible by **3** → \"Fizz\"  \n",
      "  - Numbers divisible by **5** → \"Buzz\"  \n",
      "  - Numbers divisible by **both 3 and 5 (15)** → \"FizzBuzz\"  \n",
      "  - Otherwise, the number itself.  \n",
      "\n",
      "  **Example Outputs**:  \n",
      "  3 → \"Fizz\", 5 → \"Buzz\", 15 → \"FizzBuzz\", 20 → \"Buzz\", etc.  \n",
      "\n",
      "---\n",
      "\n",
      "**University of Kent Facts**:  \n",
      "- Founded in **1965** as a polytechnic college.  \n",
      "- Located in **Canterbury (UK)** and **Medway (UK)** with online programs.  \n",
      "- Renowned for its Business School (Gold in UK rankings for Business and Management) and strong Engineering/Computational Sciences programs.  \n",
      "- Approximately **17,000+ students** (approximate figure as of the latest data before 2025).  \n",
      "- Offers programs in computing, business, social sciences, and professional courses like Chartered Management Accountancy.  \n",
      "\n",
      "*Note: Rankings and student numbers are subject to update.*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async for chunk in mcp_agent.run_stream(user_request, thread=thread, max_tokens = 3000):\n",
    "        if chunk.text:\n",
    "            print(chunk.text, end=\"\", flush=True)\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
